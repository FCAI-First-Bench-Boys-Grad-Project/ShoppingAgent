from langchain.agents import AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.agents import create_tool_calling_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field
import yaml
import uuid
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from src.states.MainState import MainState as State
from src.modules.Link import Link
from src.utils.load_system_prompt import load_system_prompt
from src.modules.llm import model
tools = []


class ResearcherOutput(BaseModel):
    """Researcher agent output schema"""
    message: str = Field(
        description="The message generated by the agent to hand over all the information it gathered for the manager agent. including the shopping list.",
    )
    thought: str = Field(
        description="The thought generated by the agent at the current step.",
    )
    isSearch: bool = Field(
        description="Whether the agent is calling the searching tool or not.",
    )
    query: str = Field(
        description="The query for the searching tool. Empty if the agent is not calling the searching tool.",
    )


llm = model.with_structured_output(ResearcherOutput)

system_prompt = load_system_prompt("researcher_agent")


scraping_schema = """title: str = Page title
summary: str = Page summary
"""
CONTEXT_WINDOW = 4


def extract_links(links: list[Link]) -> str:
    res = ''
    for link in links[0]:  # Assuming links are stored in a list of lists
        res += f"URL: {link.link}\nSummary: {link.description}\n"
    return res if res else "No links found."


def researcher_agent(state: State):
    if (state.get('links', False) and not state['isScraped']):
        # If links are already provided, return them
        return {"links": [state['links']], "isHuman": False, "next_node": "scraping_tool", "scraping_schema": scraping_schema}

    previous_thoughts = state.get("researcher_thoughts", [])
    latest_thoughts = previous_thoughts[-CONTEXT_WINDOW:]

    messages = [SystemMessage(content=system_prompt)]

    # Add previous thoughts as AI messages for context
    for thought in latest_thoughts:
        messages.append(AIMessage(content=thought.content))
    if state.get('isScraped', False):
        # If links are already scraped, return them
        messages.append(HumanMessage(content=extract_links(state['links'])))
        response = llm.invoke(messages)

        return {"messages": [HumanMessage(response.message)], "isHuman": False, "next_node": "manager"}
    messages.append(HumanMessage(content=state["messages"][-1].content))
    response = llm.invoke(messages)

    return {"messages": [AIMessage(response.query)],
            "researcher_thoughts": [AIMessage(response.thought)],
            "isHuman": False,
            "next_node": "searching_tool",
            "last_agent": "researcher_agent"
            }
