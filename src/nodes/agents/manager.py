from ast import operator
from typing import Annotated, Literal, TypedDict
from langchain.agents import AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.agents import create_tool_calling_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field
import yaml
import uuid
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from src.modules.llm import model
from src.utils.load_system_prompt import load_system_prompt
from src.states.MainState import MainState as State
from src.modules.Link import Link
# from src.modules.Thought import Thought

tools = []


system_prompt = load_system_prompt("manager_agent")


class ManagerOutput(BaseModel):
    """manager agent output schema"""
    message: str = Field(
        description="The message generated by the manager agent for the next step. This message will be sent to the next agent. It should contain all the data and information the next agent will need",
    )
    final_response: str = Field(
        description="When all information is gathered, construct the final response for the user here. This field will be empty if the agent is not finished.",
    )

    chain_of_thoughts: list[str] = Field(
        description="The thoughts generated by the agent at the current step.",
    )
    next_node: Literal['product_hunter_agent', 'researcher_agent', 'evaluator_agent', 'ask_human', 'end'] = Field(
        description="the next agent to call. Either 'product_hunter_agent' or 'researcher_agent' or 'evaluator_agent' or 'ask_human' or 'end'. If 'end', the agent has finished the task. If 'human', the agent is asking the user for more details.",
    )


# Define the function that calls the model
llm = model.with_structured_output(ManagerOutput)

CONTEXT_WINDOW = 10  # Number of previous thoughts to consider for context


def manager_agent(state: State):

    messages = [SystemMessage(content=system_prompt)]
    for thought in state.get("chain_of_thoughts", [])[-CONTEXT_WINDOW:]:
        # Add previous thoughts as AI messages for context
        messages.append(AIMessage(content=thought))
    if state.get("isHuman", False) == True:
        messages.append(HumanMessage(content=state["messages"][-1].content))
        response = llm.invoke(messages)
        return {
            "messages": [AIMessage(response.message)],
            "chain_of_thoughts": [response.chain_of_thoughts],
            "next_node": response.next_node,
            "final_response": "",
            "last_agent": "manager_agent",
            "isScraped": False,
            "links": [],
        }

    # If the agent is not human, it means it is being called by another agent
    messages.append(HumanMessage(content=state["messages"][-1].content))

    response = llm.invoke(messages)

    # If the model asks for more details, return its message to the human
    if response.next_node == "ask_human":
        return {
            "messages": [AIMessage(response.message)],
            "chain_of_thoughts": [response.chain_of_thoughts],
            "next_node": "ask_human",
            "final_response": "",
            "last_agent": "manager_agent",
            "isScraped": False,
            "links": [],
        }

    if response.final_response:
        # If the agent has finished the task, return the final response
        return {
            "messages": [AIMessage(response.final_response)],
            "chain_of_thoughts": [response.chain_of_thoughts],
            "next_node": "end",
            "final_response": response.final_response,
            "last_agent": "manager_agent",
            "isScraped": False,
            "links": [],
        }

    return {
        "messages": [AIMessage(response.message)],
        "chain_of_thoughts": [response.chain_of_thoughts],
        "next_node": response.next_node,
        "final_response": "",
        "last_agent": "manager_agent",
        "isScraped": False,
        "links": [],
    }
